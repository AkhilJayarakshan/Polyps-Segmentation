{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ebe347-79a3-4c42-9a71-2775b29cb768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print True if CUDA is available\n",
    "print(torch.cuda.get_device_name(0))  # Prints the name of your GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "041d243b-8732-422b-b42b-6472c90e9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models.segmentation as models\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9094e98-128b-4304-8d62-9163cc7c78b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Memory Allocated: 0.00 GB\n",
      "Memory Reserved: 0.00 GB\n",
      "Total Memory: 4.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"Memory Reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "    print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910be3a9-606a-4528-98de-0701e80feafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform_img=None, transform_mask=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform_img = transform_img\n",
    "        self.transform_mask = transform_mask\n",
    "        self.images = os.listdir(image_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Ensure 3 channels\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Convert mask to grayscale\n",
    "        \n",
    "        if self.transform_img:\n",
    "            image = self.transform_img(image)\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Define Separate Transformations\n",
    "transform_img = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x > 0).float())  # Binarize the mask (if needed)\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = SegmentationDataset(\"Kvasir-SEG/images\", \"Kvasir-SEG/masks\", \n",
    "                                    transform_img=transform_img, \n",
    "                                    transform_mask=transform_mask)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d484fd88-7431-484e-a43e-414d4f4dc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResUnetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResUnetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Residual connection (if input and output channels are different)\n",
    "        if in_channels != out_channels:\n",
    "            self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.res_conv(x) if hasattr(self, 'res_conv') else x  # Ensure it's defined\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x + residual)\n",
    "\n",
    "class ResUnetPlusPlus(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(ResUnetPlusPlus, self).__init__()\n",
    "        self.encoder1 = ResUnetBlock(in_channels, 64)\n",
    "        self.encoder2 = ResUnetBlock(64, 128)\n",
    "        self.encoder3 = ResUnetBlock(128, 256)\n",
    "        \n",
    "        self.middle = ResUnetBlock(256, 512)\n",
    "        \n",
    "        self.decoder3 = ResUnetBlock(512, 256)\n",
    "        self.decoder2 = ResUnetBlock(256, 128)\n",
    "        self.decoder1 = ResUnetBlock(128, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        \n",
    "        m = self.middle(e3)\n",
    "        \n",
    "        d3 = self.decoder3(m) + e3\n",
    "        d2 = self.decoder2(d3) + e2\n",
    "        d1 = self.decoder1(d2) + e1\n",
    "        \n",
    "        return self.final_conv(d1)\n",
    "\n",
    "# Now instantiate the model\n",
    "model = ResUnetPlusPlus(in_channels=3, out_channels=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd89670-cfd5-4d23-8482-600332d2f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a120c5-4d06-441a-93f9-814132a82beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.3654, IoU: 0.0873, Dice: 0.1466, Accuracy: 0.8336\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# IoU Score\n",
    "def iou_score(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred) > 0.5\n",
    "    target = target > 0.5  # Ensure target is also a binary mask\n",
    "    intersection = (pred.float() * target.float()).sum()\n",
    "    union = (pred.float() + target.float()).clamp(0, 1).sum()\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Dice Score\n",
    "def dice_score(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred) > 0.5\n",
    "    target = target > 0.5\n",
    "    intersection = (pred.float() * target.float()).sum()\n",
    "    return (2. * intersection + smooth) / (pred.float().sum() + target.float().sum() + smooth)\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    best_iou = 0.0\n",
    "    train_loss_history = []\n",
    "    train_iou_history = []\n",
    "    train_dice_history = []\n",
    "\n",
    "    # Use GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_iou = 0\n",
    "        epoch_dice = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # No ['out'] for ResUNet++\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_iou += iou_score(outputs, masks).item()\n",
    "            epoch_dice += dice_score(outputs, masks).item()\n",
    "\n",
    "            predicted = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (predicted == masks).sum().item()\n",
    "            total += masks.numel()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        epoch_loss /= len(dataloader)\n",
    "        epoch_iou /= len(dataloader)\n",
    "        epoch_dice /= len(dataloader)\n",
    "\n",
    "        train_loss_history.append(epoch_loss)\n",
    "        train_iou_history.append(epoch_iou)\n",
    "        train_dice_history.append(epoch_dice)\n",
    "\n",
    "        # Save the best model based on IoU score\n",
    "        if epoch_iou > best_iou:\n",
    "            best_iou = epoch_iou\n",
    "            torch.save(model.state_dict(), \"best_resunetpp.pth\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, IoU: {epoch_iou:.4f}, Dice: {epoch_dice:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Plot the metrics\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_loss_history, label=\"Loss\")\n",
    "    plt.title(\"Loss over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(train_iou_history, label=\"IoU\", color=\"orange\")\n",
    "    plt.title(\"IoU over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(train_dice_history, label=\"Dice\", color=\"green\")\n",
    "    plt.title(\"Dice over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Dice\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming your model, dataloader, criterion, and optimizer are already defined\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e9229-5f1d-4b36-b28c-a032c3fec915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "venv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
